{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"L2_Statistical_Significance_Solution.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"oWVD1fCh61D6"},"source":["# Practice: Statistical Significance\n","\n","Let's say that we've collected data for a web-based experiment. In the experiment, we're testing the change in layout of a product information page to see if this affects the proportion of people who click on a button to go to the download page. This experiment has been designed to have a cookie-based diversion, and we record two things from each user: which page version they received, and whether or not they accessed the download page during the data recording period. (We aren't keeping track of any other factors in this example, such as number of pageviews, or time between accessing the page and making the download, that might be of further interest.)\n","\n","Your objective in this notebook is to perform a statistical test on both recorded metrics to see if there is a statistical difference between the two groups."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"StNrGNKQ_6rq","executionInfo":{"status":"ok","timestamp":1618347081557,"user_tz":240,"elapsed":22453,"user":{"displayName":"Maria Vaghani","photoUrl":"","userId":"06148466879799234586"}},"outputId":"a8a3b707-2866-4a32-9238-35ffc0db8ed5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Af2h73NALun","executionInfo":{"status":"ok","timestamp":1618347275222,"user_tz":240,"elapsed":116,"user":{"displayName":"Maria Vaghani","photoUrl":"","userId":"06148466879799234586"}},"outputId":"0fb03c3e-093e-48ef-d968-5eaf6aa82fa7"},"source":["%cd '/content/drive/My Drive/Data Job/Colab Notebooks/Data Science Nanodegree/Exercise Files/udacity-nanodegree-exercise/5_Experimental_Design_and_Recommendations/Lesson_3_Statistical_Considerations_in_Testing'"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Data Job/Colab Notebooks/Data Science Nanodegree/Exercise Files/udacity-nanodegree-exercise/5_Experimental_Design_and_Recommendations/Lesson_3_Statistical_Considerations_in_Testing\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wns-yfunAr7N","executionInfo":{"status":"ok","timestamp":1618347281675,"user_tz":240,"elapsed":235,"user":{"displayName":"Maria Vaghani","photoUrl":"","userId":"06148466879799234586"}},"outputId":"642c1cee-eddb-4b75-8536-288548b393db"},"source":["%ls"],"execution_count":17,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdata\u001b[0m/  L2_Statistical_Significance_Solution.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z_ygQgN561EA","executionInfo":{"status":"ok","timestamp":1618347292695,"user_tz":240,"elapsed":434,"user":{"displayName":"Maria Vaghani","photoUrl":"","userId":"06148466879799234586"}}},"source":["# import packages\n","\n","import numpy as np\n","import pandas as pd\n","import scipy.stats as stats\n","from statsmodels.stats import proportion as proptests\n","\n","import matplotlib.pyplot as plt\n","% matplotlib inline"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"qRef4hN_61EB","executionInfo":{"status":"ok","timestamp":1618347313502,"user_tz":240,"elapsed":723,"user":{"displayName":"Maria Vaghani","photoUrl":"","userId":"06148466879799234586"}},"outputId":"14eeea12-1950-4576-89a9-5b1106caf073"},"source":["# import data\n","\n","data = pd.read_csv('data/statistical_significance_data.csv')\n","data.head(10)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>condition</th>\n","      <th>click</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   condition  click\n","0          1      0\n","1          0      0\n","2          0      0\n","3          1      1\n","4          1      0\n","5          1      0\n","6          0      0\n","7          1      1\n","8          0      0\n","9          1      0"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"elY09NyrUvon"},"source":["t h\n"]},{"cell_type":"markdown","metadata":{"id":"AmpHrBwS61EC"},"source":["In the dataset, the 'condition' column takes a 0 for the control group, and 1 for the experimental group. The 'click' column takes a values of 0 for no click, and 1 for a click.\n","\n","## Checking the Invariant Metric\n","\n","First of all, we should check that the number of visitors assigned to each group is similar. It's important to check the invariant metrics as a prerequisite so that our inferences on the evaluation metrics are founded on solid ground. If we find that the two groups are imbalanced on the invariant metric, then this will require us to look carefully at how the visitors were split so that any sources of bias are accounted for. It's possible that a statistically significant difference in an invariant metric will require us to revise random assignment procedures and re-do data collection.\n","\n","In this case, we want to do a two-sided hypothesis test on the proportion of visitors assigned to one of our conditions. Choosing the control or the experimental condition doesn't matter: you'll get the same result either way. Feel free to use whatever method you'd like: we'll highlight two main avenues below.\n","\n","If you want to take a simulation-based approach, you can simulate the number of visitors that would be assigned to each group for the number of total observations, assuming that we have an expected 50/50 split. Do this many times (200 000 repetitions should provide a good speed-variability balance in this case) and then see in how many simulated cases we get as extreme or more extreme a deviation from 50/50 that we actually observed. Don't forget that, since we have a two-sided test, an extreme case also includes values on the opposite side of 50/50. (e.g. Since simulated outcomes of .48 and lower are considered as being more extreme than an actual observation of 0.48, so too will simulated outcomes of .52 and higher.) The proportion of flagged simulation outcomes gives us a p-value on which to assess our observed proportion. We hope to see a larger p-value, insufficient evidence to reject the null hypothesis.\n","\n","If you want to take an analytic approach, you could use the exact binomial distribution to compute a p-value for the test. The more usual approach, however, is to use the normal distribution approximation. Recall that this is possible thanks to our large sample size and the central limit theorem. To get a precise p-value, you should also perform a \n","continuity correction, either adding or subtracting 0.5 to the total count before computing the area underneath the curve. (e.g. If we had 415 / 850 assigned to the control group, then the normal approximation would take the area to the left of $(415 + 0.5) / 850 = 0.489$ and to the right of $(435 - 0.5) / 850 = 0.511$.)\n","\n","You can check your results by completing the quiz and watching the video following the workspace. You could also try using multiple approaches and seeing if they come up with similar outcomes!"]},{"cell_type":"markdown","metadata":{"id":"2SABRzB3XNs9"},"source":["The basic z score formula for a sample is:\n","\n","z = (x – μ) / σ"]},{"cell_type":"markdown","metadata":{"id":"_qiha6ikXVND"},"source":["This z-score will tell you how many standard errors there are between the sample mean and the population mean"]},{"cell_type":"markdown","metadata":{"id":"v4zuMUkBsgkq"},"source":["#What is the Continuity Correction Factor?"]},{"cell_type":"markdown","metadata":{"id":"WHiJTp7AsdIn"},"source":["\n","A continuity correction factor is used when you use a continuous probability distribution to approximate a discrete probability distribution. For example, when you want to use the normal to approximate a binomial.\n","\n","According to the Central Limit Theorem, the sample mean of a distribution becomes approximately normal if the sample size is “large enough.” for example, the binomial distribution can be approximated with a normal distribution as long as n*p and n*q are both at least 5. Here,\n","\n","n = how many items are in your sample,\n","p = probability of an event (e.g. 60%),\n","q = probability the event doesn’t happen (100% – p).\n","The continuity correction factor accounts for the fact that a normal distribution is continuous, and a binomial is not. When you use a normal distribution to approximate a binomial distribution, you’re going to have to use a continuity correction factor. It’s as simple as adding or subtracting .5 to the discrete x-value: use the following table to decide whether to add or subtract."]},{"cell_type":"markdown","metadata":{"id":"O7sQcwpOMbP1"},"source":["formula for z = (x - m)/std\n","\n","for binomial distribution x the number of successes for a group\n","plus or minus 0.5 to get closer to the middle between them"]},{"cell_type":"code","metadata":{"id":"Ca4HargnPDsh","executionInfo":{"status":"ok","timestamp":1618359218634,"user_tz":240,"elapsed":167,"user":{"displayName":"Maria Vaghani","photoUrl":"","userId":"06148466879799234586"}}},"source":["#number of trials in binomial experiment\n","n = data.shape[0] #all trials\n","\n","#formula for z = (x - m)/std\n","x = data[data['condition']==0].shape[0] + 0.5 #the sample of control group corrected\n","m = n*0.5 #distribution mean\n","sd = np.sqrt(n * 0.5 * 0.5)"],"execution_count":121,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2vodpM8MtFSY","executionInfo":{"status":"ok","timestamp":1618359219180,"user_tz":240,"elapsed":151,"user":{"displayName":"Maria Vaghani","photoUrl":"","userId":"06148466879799234586"}},"outputId":"9355eb30-9f92-4eeb-a5e6-c374b28a7c38"},"source":["#is sample large enough\n","n*0.5"],"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["499.5"]},"metadata":{"tags":[]},"execution_count":122}]},{"cell_type":"markdown","metadata":{"id":"BTR3DFVIt_cj"},"source":["Yes, n*0.5 is more than 5"]},{"cell_type":"code","metadata":{"id":"3CwRPrLtMSYT","executionInfo":{"status":"ok","timestamp":1618359220719,"user_tz":240,"elapsed":152,"user":{"displayName":"Maria Vaghani","photoUrl":"","userId":"06148466879799234586"}}},"source":["#formula for z = (x - m)/std\n","z = (x - m)/ sd"],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rG-iFDiNeAg","executionInfo":{"status":"ok","timestamp":1618359227648,"user_tz":240,"elapsed":182,"user":{"displayName":"Maria Vaghani","photoUrl":"","userId":"06148466879799234586"}},"outputId":"843ff988-4285-4650-ab54-6c08f9575395"},"source":["#z value of a sample control group\n","z"],"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-0.5062175977346661"]},"metadata":{"tags":[]},"execution_count":125}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gv99GkQcuved","executionInfo":{"status":"ok","timestamp":1618359658387,"user_tz":240,"elapsed":156,"user":{"displayName":"Maria Vaghani","photoUrl":"","userId":"06148466879799234586"}},"outputId":"0b97aa2d-413f-4b85-e22a-eace5a2edf63"},"source":["2*stats.norm.sf(abs(z))"],"execution_count":128,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6127039025537114"]},"metadata":{"tags":[]},"execution_count":128}]},{"cell_type":"markdown","metadata":{"id":"hNFgBQWH61ED"},"source":["### Analytic Approach"]},{"cell_type":"code","metadata":{"id":"R15nBOI961ED","executionInfo":{"status":"ok","timestamp":1618350200516,"user_tz":240,"elapsed":163,"user":{"displayName":"Maria Vaghani","photoUrl":"","userId":"06148466879799234586"}}},"source":["# get number of trials and number of 'successes'\n","n_obs = data.shape[0]\n","n_control = data.groupby('condition').size()[0]"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_g7zrsOMF5U","executionInfo":{"status":"ok","timestamp":1618358994827,"user_tz":240,"elapsed":503,"user":{"displayName":"Maria Vaghani","photoUrl":"","userId":"06148466879799234586"}},"outputId":"04477a5c-d2bb-40e4-de7a-45072b76297b"},"source":["data.groupby('condition').size()"],"execution_count":118,"outputs":[{"output_type":"execute_result","data":{"text/plain":["condition\n","0    491\n","1    508\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":118}]},{"cell_type":"code","metadata":{"id":"XkC4z3vH61EE","outputId":"c7773f33-3219-4d6d-9bf1-44234f7fbbc8"},"source":["# Compute a z-score and p-value\n","p = 0.5\n","sd = np.sqrt(p * (1-p) * n_obs)\n","\n","z = ((n_control + 0.5) - p * n_obs) / sd\n","\n","print(z)\n","print(2 * stats.norm.cdf(z))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-0.506217597735\n","0.612703902554\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tFQ4P0cl61EF"},"source":["### Simulation Approach"]},{"cell_type":"code","metadata":{"id":"t02lfrMI61EF"},"source":["# get number of trials and number of 'successes'\n","n_obs = data.shape[0]\n","n_control = data.groupby('condition').size()[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RcuwdLbH61EG","outputId":"49c82b97-2312-433c-df68-764ae887d728"},"source":["# # simulate outcomes under null, compare to observed outcome\n","p = 0.5\n","n_trials = 200_000\n","\n","samples = np.random.binomial(n_obs, p, n_trials)\n","\n","print(np.logical_or(samples <= n_control, samples >= (n_obs - n_control)).mean())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.611725\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-Pj9_YT361EG"},"source":["## Checking the Evaluation Metric\n","\n","After performing our checks on the invariant metric, we can move on to performing a hypothesis test on the evaluation metric: the click-through rate. In this case, we want to see that the experimental group has a significantly larger click-through rate than the control group, a one-tailed test.\n","\n","The simulation approach for this metric isn't too different from the approach for the invariant metric. You'll need the overall click-through rate as the common proportion to draw simulated values from for each group. You may also want to perform more simulations since there's higher variance for this test.\n","\n","There's a few analytic approaches possible here, but you'll probably make use of the normal approximation again in these cases. In addition to the pooled click-through rate, you'll need a pooled standard deviation in order to compute a z-score. While there is a continuity correction possible in this case as well, it's much more conservative than the p-value that a simulation will usually imply. Computing the z-score and resulting p-value without a continuity correction should be closer to the simulation's outcomes, though slightly more optimistic about there being a statistical difference between groups.\n","\n","As with the previous question, you'll find a quiz and video following the workspace for you to check your results."]},{"cell_type":"code","metadata":{"id":"frv_Fova61EH","outputId":"9ebfd232-f4f1-4015-f1f7-26dd720a1b66"},"source":["p_click = data.groupby('condition').mean()['click']\n","p_click"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["condition\n","0    0.079430\n","1    0.112205\n","Name: click, dtype: float64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"GWEn2FuG61EH","outputId":"b0aeacbc-065f-4066-cdd3-af36cfc9355a"},"source":["p_click[1] - p_click[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.03277498917523293"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"9lqw1Wax61EH"},"source":["### Analytic Approach"]},{"cell_type":"code","metadata":{"id":"nvq_bWF861EH"},"source":["# get number of trials and overall 'success' rate under null\n","n_control = data.groupby('condition').size()[0]\n","n_exper = data.groupby('condition').size()[1]\n","p_null = data['click'].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qc5OaKyY61EI","outputId":"4680d094-38bc-43c4-b23c-be3a1a1fe9a8"},"source":["# compute standard error, z-score, and p-value\n","se_p = np.sqrt(p_null * (1-p_null) * (1/n_control + 1/n_exper))\n","\n","z = (p_click[1] - p_click[0]) / se_p\n","print(z)\n","print(1-stats.norm.cdf(z))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.75718873962\n","0.0394428219746\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wW0HseRC61EI"},"source":["### Simulation Approach"]},{"cell_type":"code","metadata":{"id":"hb_EIF3W61EI"},"source":["# get number of trials and overall 'success' rate under null\n","n_control = data.groupby('condition').size()[0]\n","n_exper = data.groupby('condition').size()[1]\n","p_null = data['click'].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-j85ixa61EI","outputId":"bd8cdfd2-eaa7-4e61-ce11-48963991acb3"},"source":["# simulate outcomes under null, compare to observed outcome\n","n_trials = 200_000\n","\n","ctrl_clicks = np.random.binomial(n_control, p_null, n_trials)\n","exp_clicks = np.random.binomial(n_exper, p_null, n_trials)\n","samples = exp_clicks / n_exper - ctrl_clicks / n_control\n","\n","print((samples >= (p_click[1] - p_click[0])).mean())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.039785\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1sruLHWtx-d5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UkV_mC_Wx-ae"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d7RGAAPtyBuy"},"source":[" Remember that the variance of the difference distribution is the sum of the variances for the individual distributions, and that each group is assigned n observations."]},{"cell_type":"code","metadata":{"id":"t7lJ4OKXyCR1"},"source":["var1 = n * p_null * (1-p_null)\n","var_alt = n * p_alt * (1-p_alt)\n","\n","sum = np.sqrt(n * p_null * (1-p_null) + n * p_alt * (1-p_alt))"],"execution_count":null,"outputs":[]}]}