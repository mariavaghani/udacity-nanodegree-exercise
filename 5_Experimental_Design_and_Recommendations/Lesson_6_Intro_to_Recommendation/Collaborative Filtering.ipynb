{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1621004033321,
     "user": {
      "displayName": "Maria Vaghani",
      "photoUrl": "",
      "userId": "06148466879799234586"
     },
     "user_tz": 240
    },
    "id": "EXFDB2I71l4u",
    "outputId": "077bec74-ba3d-41fe-95ed-4ca26d751448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1621004034032,
     "user": {
      "displayName": "Maria Vaghani",
      "photoUrl": "",
      "userId": "06148466879799234586"
     },
     "user_tz": 240
    },
    "id": "wSBj_Xbt1kkl",
    "outputId": "52611a30-e25d-4079-d300-589d2902859c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Data Job/Colab Notebooks/Data Science Nanodegree/Exercise Files/udacity-nanodegree-exercise/5_Experimental_Design_and_Recommendations/Lesson_6_Intro_to_Recommendation\n"
     ]
    }
   ],
   "source": [
    "%cd \"/content/drive/My Drive/Data Job/Colab Notebooks/Data Science Nanodegree/Exercise Files/udacity-nanodegree-exercise/5_Experimental_Design_and_Recommendations/Lesson_6_Intro_to_Recommendation/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 444,
     "status": "ok",
     "timestamp": 1621004034940,
     "user": {
      "displayName": "Maria Vaghani",
      "photoUrl": "",
      "userId": "06148466879799234586"
     },
     "user_tz": 240
    },
    "id": "Hu9EZPnp2DBf",
    "outputId": "33ac8a5c-07f3-4585-a78f-55d2071311f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " all_recs.p                                       movies_clean.csv\n",
      "'Collaborative Filtering.ipynb'                   movies.dat\n",
      " helper.py                                        \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
      "'Introduction to the Recommendation Data.ipynb'   ratings.dat\n",
      "'Measuring Similarity.ipynb'                      reviews_clean.csv\n",
      "'Measuring Similarity - Solution.ipynb'           tests.py\n",
      " Most_Popular_Recommendations.ipynb\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzh8lfyw1TuG"
   },
   "source": [
    "## Recommendations with MovieTweetings: Collaborative Filtering\n",
    "\n",
    "One of the most popular methods for making recommendations is **collaborative filtering**.  In collaborative filtering, you are using the collaboration of user-item recommendations to assist in making new recommendations.  \n",
    "\n",
    "There are two main methods of performing collaborative filtering:\n",
    "\n",
    "1. **Neighborhood-Based Collaborative Filtering**, which is based on the idea that we can either correlate items that are similar to provide recommendations or we can correlate users to one another to provide recommendations.\n",
    "\n",
    "2. **Model Based Collaborative Filtering**, which is based on the idea that we can use machine learning and other mathematical models to understand the relationships that exist amongst items and users to predict ratings and provide ratings.\n",
    "\n",
    "\n",
    "In this notebook, you will be working on performing **neighborhood-based collaborative filtering**.  There are two main methods for performing collaborative filtering:\n",
    "\n",
    "1. **User-based collaborative filtering:** In this type of recommendation, users related to the user you would like to make recommendations for are used to create a recommendation.\n",
    "\n",
    "2. **Item-based collaborative filtering:** In this type of recommendation, first you need to find the items that are most related to each other item (based on similar ratings).  Then you can use the ratings of an individual on those similar items to understand if a user will like the new item.\n",
    "\n",
    "In this notebook you will be implementing **user-based collaborative filtering**.  However, it is easy to extend this approach to make recommendations using **item-based collaborative filtering**.  First, let's read in our data and necessary libraries.\n",
    "\n",
    "**NOTE**: Because of the size of the datasets, some of your code cells here will take a while to execute, so be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6292,
     "status": "ok",
     "timestamp": 1621004042926,
     "user": {
      "displayName": "Maria Vaghani",
      "photoUrl": "",
      "userId": "06148466879799234586"
     },
     "user_tz": 240
    },
    "id": "eN1kwnE_1TuL",
    "outputId": "cee99509-dc56-494c-f476-da1693383f88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating   timestamp                 date  month_1  \\\n",
      "0        1     68646      10  1381620027  2013-10-12 23:20:27        0   \n",
      "1        1    113277      10  1379466669  2013-09-18 01:11:09        0   \n",
      "2        2    422720       8  1412178746  2014-10-01 15:52:26        0   \n",
      "3        2    454876       8  1394818630  2014-03-14 17:37:10        0   \n",
      "4        2    790636       7  1389963947  2014-01-17 13:05:47        0   \n",
      "\n",
      "   month_2  month_3  month_4  month_5  ...  month_9  month_10  month_11  \\\n",
      "0        0        0        0        0  ...        0         1         0   \n",
      "1        0        0        0        0  ...        0         0         0   \n",
      "2        0        0        0        0  ...        0         1         0   \n",
      "3        0        0        0        0  ...        0         0         0   \n",
      "4        0        0        0        0  ...        0         0         0   \n",
      "\n",
      "   month_12  year_2013  year_2014  year_2015  year_2016  year_2017  year_2018  \n",
      "0         0          1          0          0          0          0          0  \n",
      "1         0          1          0          0          0          0          0  \n",
      "2         0          0          1          0          0          0          0  \n",
      "3         0          0          1          0          0          0          0  \n",
      "4         0          0          1          0          0          0          0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tests as t\n",
    "from scipy.sparse import csr_matrix\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('movies_clean.csv')\n",
    "reviews = pd.read_csv('reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']\n",
    "\n",
    "print(reviews.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go_0au2F1TuM"
   },
   "source": [
    "### Measures of Similarity\n",
    "\n",
    "When using **neighborhood** based collaborative filtering, it is important to understand how to measure the similarity of users or items to one another.  \n",
    "\n",
    "There are a number of ways in which we might measure the similarity between two vectors (which might be two users or two items).  In this notebook, we will look specifically at two measures used to compare vectors:\n",
    "\n",
    "* **Pearson's correlation coefficient**\n",
    "\n",
    "Pearson's correlation coefficient is a measure of the strength and direction of a linear relationship. The value for this coefficient is a value between -1 and 1 where -1 indicates a strong, negative linear relationship and 1 indicates a strong, positive linear relationship. \n",
    "\n",
    "If we have two vectors x and y, we can define the correlation between the vectors as:\n",
    "\n",
    "\n",
    "$$CORR(x, y) = \\frac{\\text{COV}(x, y)}{\\text{STDEV}(x)\\text{ }\\text{STDEV}(y)}$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\\text{STDEV}(x) = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\text{COV}(x, y) = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})$$\n",
    "\n",
    "where n is the length of the vector, which must be the same for both x and y and $\\bar{x}$ is the mean of the observations in the vector.  \n",
    "\n",
    "We can use the correlation coefficient to indicate how alike two vectors are to one another, where the closer to 1 the coefficient, the more alike the vectors are to one another.  There are some potential downsides to using this metric as a measure of similarity.  You will see some of these throughout this workbook.\n",
    "\n",
    "\n",
    "* **Euclidean distance**\n",
    "\n",
    "Euclidean distance is a measure of the straightline distance from one vector to another.  Because this is a measure of distance, larger values are an indication that two vectors are different from one another (which is different than Pearson's correlation coefficient).\n",
    "\n",
    "Specifically, the euclidean distance between two vectors x and y is measured as:\n",
    "\n",
    "$$ \\text{EUCL}(x, y) = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2}$$\n",
    "\n",
    "Different from the correlation coefficient, no scaling is performed in the denominator.  Therefore, you need to make sure all of your data are on the same scale when using this metric.\n",
    "\n",
    "**Note:** Because measuring similarity is often based on looking at the distance between vectors, it is important in these cases to scale your data or to have all data be in the same scale.  If some measures are on a 5 point scale, while others are on a 100 point scale, you are likely to have non-optimal results due to the difference in variability of your features.  In this case, we will not need to scale data because they are all on a 10 point scale, but it is always something to keep in mind!\n",
    "\n",
    "------------\n",
    "\n",
    "### User-Item Matrix\n",
    "\n",
    "In order to calculate the similarities, it is common to put values in a matrix.  In this matrix, users are identified by each row, and items are represented by columns.  \n",
    "\n",
    "\n",
    "![alt text](images/userxitem.png \"User Item Matrix\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a77IuseR1TuN"
   },
   "source": [
    "In the above matrix, you can see that **User 1** and **User 2** both used **Item 1**, and **User 2**, **User 3**, and **User 4** all used **Item 2**.  However, there are also a large number of missing values in the matrix for users who haven't used a particular item.  A matrix with many missing values (like the one above) is considered **sparse**.\n",
    "\n",
    "Our first goal for this notebook is to create the above matrix with the **reviews** dataset.  However, instead of 1 values in each cell, you should have the actual rating.  \n",
    "\n",
    "The users will indicate the rows, and the movies will exist across the columns. To create the user-item matrix, we only need the first three columns of the **reviews** dataframe, which you can see by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1621004043607,
     "user": {
      "displayName": "Maria Vaghani",
      "photoUrl": "",
      "userId": "06148466879799234586"
     },
     "user_tz": 240
    },
    "id": "Z3JJGz5g1TuN",
    "outputId": "888cb2d9-0506-4115-f332-1b27fccd7f99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>68646</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>113277</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>422720</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>454876</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>790636</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0        1     68646      10\n",
       "1        1    113277      10\n",
       "2        2    422720       8\n",
       "3        2    454876       8\n",
       "4        2    790636       7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_items = reviews[['user_id', 'movie_id', 'rating']]\n",
    "user_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCUp2zNG1TuO"
   },
   "source": [
    "### Creating the User-Item Matrix\n",
    "\n",
    "In order to create the user-items matrix (like the one above), I personally started by using a [pivot table](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html). \n",
    "\n",
    "However, I quickly ran into a memory error (a common theme throughout this notebook).  I will help you navigate around many of the errors I had, and achieve useful collaborative filtering results! \n",
    "\n",
    "_____\n",
    "\n",
    "`1.` Create a matrix where the users are the rows, the movies are the columns, and the ratings exist in each cell, or a NaN exists in cells where a user hasn't rated a particular movie. If you get a memory error (like I did), [this link here](https://stackoverflow.com/questions/39648991/pandas-dataframe-pivot-memory-error) might help you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1711,
     "status": "ok",
     "timestamp": 1620997450885,
     "user": {
      "displayName": "Maria Vaghani",
      "photoUrl": "",
      "userId": "06148466879799234586"
     },
     "user_tz": 240
    },
    "id": "f4_A4QUc1TuO"
   },
   "outputs": [],
   "source": [
    "# Create user-by-item matrix\n",
    "user_by_movie = user_items.groupby(['user_id', 'movie_id'])['rating'].max().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dodFGTDG1TuP"
   },
   "source": [
    "Check your results below to make sure your matrix is ready for the upcoming sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y5v1pm-h1TuP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like you are all set! Proceed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"images/greatjob.webp\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert movies.shape[0] == user_by_movie.shape[1], \"Oh no! Your matrix should have {} columns, and yours has {}!\".format(movies.shape[0], user_by_movie.shape[1])\n",
    "assert reviews.user_id.nunique() == user_by_movie.shape[0], \"Oh no! Your matrix should have {} rows, and yours has {}!\".format(reviews.user_id.nunique(), user_by_movie.shape[0])\n",
    "print(\"Looks like you are all set! Proceed!\")\n",
    "HTML('<img src=\"images/greatjob.webp\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAVPjJl01TuP"
   },
   "source": [
    "`2.` Now that you have a matrix of users by movies, use this matrix to create a dictionary where the key is each user and the value is an array of the movies each user has rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>25</th>\n",
       "      <th>91</th>\n",
       "      <th>417</th>\n",
       "      <th>439</th>\n",
       "      <th>443</th>\n",
       "      <th>628</th>\n",
       "      <th>833</th>\n",
       "      <th>...</th>\n",
       "      <th>8144778</th>\n",
       "      <th>8144868</th>\n",
       "      <th>8206708</th>\n",
       "      <th>8289196</th>\n",
       "      <th>8324578</th>\n",
       "      <th>8335880</th>\n",
       "      <th>8342748</th>\n",
       "      <th>8342946</th>\n",
       "      <th>8402090</th>\n",
       "      <th>8439854</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31245 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  8        10       12       25       91       417      439      \\\n",
       "user_id                                                                   \n",
       "1             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "3             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "4             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "5             NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "movie_id  443      628      833      ...  8144778  8144868  8206708  8289196  \\\n",
       "user_id                              ...                                       \n",
       "1             NaN      NaN      NaN  ...      NaN      NaN      NaN      NaN   \n",
       "2             NaN      NaN      NaN  ...      NaN      NaN      NaN      NaN   \n",
       "3             NaN      NaN      NaN  ...      NaN      NaN      NaN      NaN   \n",
       "4             NaN      NaN      NaN  ...      NaN      NaN      NaN      NaN   \n",
       "5             NaN      NaN      NaN  ...      NaN      NaN      NaN      NaN   \n",
       "\n",
       "movie_id  8324578  8335880  8342748  8342946  8402090  8439854  \n",
       "user_id                                                         \n",
       "1             NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "2             NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "3             NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "4             NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "5             NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 31245 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_by_movie.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id\n",
       "1790864    7.0\n",
       "2170439    7.0\n",
       "2203939    6.0\n",
       "Name: 3, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 3\n",
    "user_by_movie.loc[user_id][user_by_movie.loc[user_id].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "B9SISR0M1TuP"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary with users and corresponding movies seen\n",
    "\n",
    "def movies_watched(user_id):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id of an individual as int\n",
    "    OUTPUT:\n",
    "    movies - an array of movies the user has watched\n",
    "    '''\n",
    "    \n",
    "    return user_by_movie.loc[user_id][user_by_movie.loc[user_id].notnull()]\n",
    "\n",
    "\n",
    "def create_user_movie_dict():\n",
    "    '''\n",
    "    INPUT: None\n",
    "    OUTPUT: movies_seen - a dictionary where each key is a user_id and the value is an array of movie_ids\n",
    "    \n",
    "    Creates the movies_seen dictionary\n",
    "    '''\n",
    "    movies_seen = {}\n",
    "    \n",
    "    for user in user_by_movie.index:\n",
    "        movies_seen[user] = movies_watched(user)\n",
    "    \n",
    "    return movies_seen\n",
    "\n",
    "\n",
    "# Use your function to return dictionary\n",
    "movies_seen = create_user_movie_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_seen[45].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MlitP2E1TuQ"
   },
   "source": [
    "`3.` If a user hasn't rated more than 2 movies, we consider these users \"too new\".  Create a new dictionary that only contains users who have rated more than 2 movies.  This dictionary will be used for all the final steps of this workbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "zucbQbJ01TuQ"
   },
   "outputs": [],
   "source": [
    "# Remove individuals who have watched 2 or fewer movies - don't have enough data to make recs\n",
    "\n",
    "def create_movies_to_analyze(movies_seen, lower_bound=2):\n",
    "    '''\n",
    "    INPUT:  \n",
    "    movies_seen - a dictionary where each key is a user_id and the value is an array of movie_ids\n",
    "    lower_bound - (an int) a user must have more movies seen than the lower bound to be added to the movies_to_analyze dictionary\n",
    "\n",
    "    OUTPUT: \n",
    "    movies_to_analyze - a dictionary where each key is a user_id and the value is an array of movie_ids\n",
    "    \n",
    "    The movies_seen and movies_to_analyze dictionaries should be the same except that the output dictionary has removed \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    movies_to_analyze = { key:value for (key,value) in movies_seen.items() if value.shape[0] > lower_bound }\n",
    "    \n",
    "    return movies_to_analyze\n",
    "\n",
    "\n",
    "# Use your function to return your updated dictionary\n",
    "movies_to_analyze = create_movies_to_analyze(movies_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "xu8AerjR1TuQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, you are good to go!\n"
     ]
    }
   ],
   "source": [
    "# Run the tests below to check that your movies_to_analyze matches the solution\n",
    "assert len(movies_to_analyze) == 23512, \"Oops!  It doesn't look like your dictionary has the right number of individuals.\"\n",
    "assert len(movies_to_analyze[2]) == 23, \"Oops!  User 2 didn't match the number of movies we thought they would have.\"\n",
    "assert len(movies_to_analyze[7])  == 3, \"Oops!  User 7 didn't match the number of movies we thought they would have.\"\n",
    "print(\"If this is all you see, you are good to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJv-eKCN1TuQ"
   },
   "source": [
    "### Calculating User Similarities\n",
    "\n",
    "Now that you have set up the **movies_to_analyze** dictionary, it is time to take a closer look at the similarities between users.  Below is the pseudocode for how I thought about determining the similarity between users:\n",
    "\n",
    "```\n",
    "for user1 in movies_to_analyze\n",
    "    for user2 in movies_to_analyze\n",
    "        see how many movies match between the two users\n",
    "        if more than two movies in common\n",
    "            pull the overlapping movies\n",
    "            compute the distance/similarity metric between ratings on the same movies for the two users\n",
    "            store the users and the distance metric\n",
    "```\n",
    "\n",
    "However, this took a very long time to run, and other methods of performing these operations did not fit on the workspace memory!\n",
    "\n",
    "Therefore, rather than creating a dataframe with all possible pairings of users in our data, your task for this question is to look at a few specific examples of the correlation between ratings given by two users.  For this question consider you want to compute the [correlation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html) between users.\n",
    "\n",
    "`4.` Using the **movies_to_analyze** dictionary and **user_by_movie** dataframe, create a function that computes the correlation between the ratings of similar movies for two users.  Then use your function to compare your results to ours using the tests below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr, kendalltau\n",
    "user1 = 2\n",
    "user2 = 2\n",
    "common_movies = pd.concat([movies_to_analyze[user1], movies_to_analyze[user2]], axis=1, join=\"inner\")\n",
    "common_movies.corr()[user1][user2]\n",
    "all(movies_to_analyze[user1] == movies_to_analyze[user2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  7.,  8.,\n",
       "        8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "        8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  9., 10.,\n",
       "       10., 10.])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.intersect1d(movies_to_analyze[user1], movies_to_analyze[user2], assume_unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "WTmL2iVO1TuR"
   },
   "outputs": [],
   "source": [
    "def compute_correlation(user1, user2):\n",
    "    '''\n",
    "    INPUT\n",
    "    user1 - int user_id\n",
    "    user2 - int user_id\n",
    "    OUTPUT\n",
    "    the correlation between the matching ratings between the two users\n",
    "    '''\n",
    "    common_movies = pd.concat([movies_to_analyze[user1], movies_to_analyze[user2]], axis=1, join=\"inner\")\n",
    "    if user1 == user2:\n",
    "        return 1 \n",
    "    return common_movies.corr()[user1][user2] #return the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  10\n",
       "user_id     \n",
       "2        NaN\n",
       "104      NaN"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_by_movie.loc[[user1, user2], [10]]\n",
    "# sim_mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 422720,  454876,  790636,  816711, 1091191, 1103275, 1322269,\n",
       "            1390411, 1398426, 1431045, 1433811, 1454468, 1535109, 1675434,\n",
       "            1798709, 2017038, 2024544, 2294629, 2361509, 2381249, 2726560,\n",
       "            2883512, 3079380],\n",
       "           dtype='int64', name='movie_id')"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_to_analyze[user1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movie_id</th>\n",
       "      <th>1454468</th>\n",
       "      <th>1798709</th>\n",
       "      <th>2883512</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movie_id  1454468  1798709  2883512\n",
       "user_id                            \n",
       "2             8.0     10.0      8.0\n",
       "66            6.0      9.0      8.0"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1 = 2\n",
    "user2 = 66\n",
    "movies1 = movies_to_analyze[user1].index\n",
    "movies2 = movies_to_analyze[user2].index\n",
    "\n",
    "sim_mov = np.intersect1d(movies1, movies2, assume_unique = True)\n",
    "\n",
    "user_by_movie.loc[[user1, user2], sim_mov]\n",
    "\n",
    "# df.transpose().corr().iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((movies_to_analyze[user1] - movies_to_analyze[user2]) **2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "67t63pq11TuR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this is all you see, then it looks like your function passed all of our tests!\n"
     ]
    }
   ],
   "source": [
    "# Test your function against the solution\n",
    "assert compute_correlation(2,2) == 1.0, \"Oops!  The correlation between a user and itself should be 1.0.\"\n",
    "assert round(compute_correlation(2,66), 2) == 0.76, \"Oops!  The correlation between user 2 and 66 should be about 0.76.\"\n",
    "assert np.isnan(compute_correlation(2,104)), \"Oops!  The correlation between user 2 and 104 should be a NaN.\"\n",
    "\n",
    "print(\"If this is all you see, then it looks like your function passed all of our tests!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwnO0Ldu1TuR"
   },
   "source": [
    "### Why the NaN's?\n",
    "\n",
    "If the function you wrote passed all of the tests, then you have correctly set up your function to calculate the correlation between any two users.  \n",
    "\n",
    "`5.` But one question is, why are we still obtaining **NaN** values?  As you can see in the code cell above, users 2 and 104 have a correlation of **NaN**. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkv6PFbE1TuR"
   },
   "source": [
    "Think and write your ideas here about why these NaNs exist, and use the cells below to do some coding to validate your thoughts. You can check other pairs of users and see that there are actually many NaNs in our data - 2,526,710 of them in fact. These NaN's ultimately make the correlation coefficient a less than optimal measure of similarity between two users.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "id": "gxqxS_iR1TuR"
   },
   "outputs": [],
   "source": [
    "# Which movies did both user 2 and user 104 see?\n",
    "user1 = 2\n",
    "user2 = 104\n",
    "mov_2_104 = pd.concat([movies_to_analyze[user1], movies_to_analyze[user2]], axis=1, join=\"inner\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "id": "nBRIjvxy1TuS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13676          Life of Pi (2012)\n",
       "14754         World War Z (2013)\n",
       "17747             Gravity (2013)\n",
       "18168    Captain Phillips (2013)\n",
       "Name: movie, dtype: object"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What were the ratings for each user for those movies?\n",
    "mov_2_104['movie_id']\n",
    "movies[movies['movie_id'].isin(mov_2_104['movie_id'])]['movie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rjltPvO1TuS"
   },
   "source": [
    "`6.` Because the correlation coefficient proved to be less than optimal for relating user ratings to one another, we could instead calculate the euclidean distance between the ratings.  I found [this post](https://stackoverflow.com/questions/1401712/how-can-the-euclidean-distance-be-calculated-with-numpy) particularly helpful when I was setting up my function.  This function should be very similar to your previous function.  When you feel confident with your function, test it against our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "6Dem1wlC1TuS"
   },
   "outputs": [],
   "source": [
    "def compute_euclidean_dist(user1, user2):\n",
    "    '''\n",
    "    INPUT\n",
    "    user1 - int user_id\n",
    "    user2 - int user_id\n",
    "    OUTPUT\n",
    "    the euclidean distance between user1 and user2\n",
    "    '''\n",
    "    return np.sqrt(np.sum((movies_to_analyze[user1] - movies_to_analyze[user2]) ** 2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_euclidean_dist(user1, user2):\n",
    "    '''\n",
    "    INPUT\n",
    "    user1 - int user_id\n",
    "    user2 - int user_id\n",
    "    OUTPUT\n",
    "    the euclidean distance between user1 and user2\n",
    "    '''\n",
    "    movies1 = movies_to_analyze[user1].index\n",
    "    movies2 = movies_to_analyze[user2].index\n",
    "\n",
    "    sim_mov = np.intersect1d(movies1, movies2, assume_unique = True)\n",
    "\n",
    "    df = user_by_movie.loc[[user1, user2], sim_mov]\n",
    "\n",
    "    \n",
    "    return np.linalg.norm(df.loc[user1] - df.loc[user2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_euclidean_dist(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "W3qFu3i41TuS"
   },
   "outputs": [],
   "source": [
    "# Read in solution euclidean distances\n",
    "import pickle\n",
    "df_dists = pd.read_pickle(\"dists.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aJ-vIZkX1TuS"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_euclidean_dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-6a0965636c65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test your function against the solution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mcompute_euclidean_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdf_dists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user1 == 2 and user2 == 2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eucl_dist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Oops!  The distance between a user and itself should be 0.0.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_euclidean_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m66\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_dists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user1 == 2 and user2 == 66\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eucl_dist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Oops!  The distance between user 2 and 66 should be about 2.24.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_euclidean_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m104\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_dists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user1 == 2 and user2 == 104\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eucl_dist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Oops!  The distance between user 2 and 104 should be 2.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compute_euclidean_dist' is not defined"
     ]
    }
   ],
   "source": [
    "# Test your function against the solution\n",
    "assert compute_euclidean_dist(2,2) == df_dists.query(\"user1 == 2 and user2 == 2\")['eucl_dist'][0], \"Oops!  The distance between a user and itself should be 0.0.\"\n",
    "assert round(compute_euclidean_dist(2,66), 2) == round(df_dists.query(\"user1 == 2 and user2 == 66\")['eucl_dist'][1], 2), \"Oops!  The distance between user 2 and 66 should be about 2.24.\"\n",
    "assert np.isnan(compute_euclidean_dist(2,104)) == np.isnan(df_dists.query(\"user1 == 2 and user2 == 104\")['eucl_dist'][4]), \"Oops!  The distance between user 2 and 104 should be 2.\"\n",
    "\n",
    "print(\"If this is all you see, then it looks like your function passed all of our tests!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuHRqbWX1TuS"
   },
   "source": [
    "### Using the Nearest Neighbors to Make Recommendations\n",
    "\n",
    "In the previous question, you read in **df_dists**. Therefore, you have a measure of distance between each user and every other user. This dataframe holds every possible pairing of users, as well as the corresponding euclidean distance.\n",
    "\n",
    "Because of the **NaN** values that exist within the correlations of the matching ratings for many pairs of users, as we discussed above, we will proceed using **df_dists**. You will want to find the users that are 'nearest' each user.  Then you will want to find the movies the closest neighbors have liked to recommend to each user.\n",
    "\n",
    "I made use of the following objects:\n",
    "\n",
    "* df_dists (to obtain the neighbors)\n",
    "* user_items (to obtain the movies the neighbors and users have rated)\n",
    "* movies (to obtain the names of the movies)\n",
    "\n",
    "`7.` Complete the functions below, which allow you to find the recommendations for any user.  There are five functions which you will need:\n",
    "\n",
    "* **find_closest_neighbors** - this returns a list of user_ids from closest neighbor to farthest neighbor using euclidean distance\n",
    "\n",
    "\n",
    "* **movies_liked** - returns an array of movie_ids\n",
    "\n",
    "\n",
    "* **movie_names** - takes the output of movies_liked and returns a list of movie names associated with the movie_ids\n",
    "\n",
    "\n",
    "* **make_recommendations** - takes a user id and goes through closest neighbors to return a list of movie names as recommendations\n",
    "\n",
    "\n",
    "* **all_recommendations** = loops through every user and returns a dictionary of with the key as a user_id and the value as a list of movie recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user1</th>\n",
       "      <th>user2</th>\n",
       "      <th>eucl_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>2</td>\n",
       "      <td>52737</td>\n",
       "      <td>11.916375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>2</td>\n",
       "      <td>32494</td>\n",
       "      <td>11.532563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>2</td>\n",
       "      <td>36807</td>\n",
       "      <td>10.862780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2</td>\n",
       "      <td>3514</td>\n",
       "      <td>10.440307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>2</td>\n",
       "      <td>49739</td>\n",
       "      <td>10.344080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>2</td>\n",
       "      <td>30884</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>2</td>\n",
       "      <td>33207</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>2</td>\n",
       "      <td>32951</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>755</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2809 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user1  user2  eucl_dist\n",
       "2743      2  52737  11.916375\n",
       "1699      2  32494  11.532563\n",
       "1915      2  36807  10.862780\n",
       "165       2   3514  10.440307\n",
       "2575      2  49739  10.344080\n",
       "...     ...    ...        ...\n",
       "1590      2  30884   0.000000\n",
       "1729      2  33207   0.000000\n",
       "1719      2  32951   0.000000\n",
       "35        2    755   0.000000\n",
       "0         2      2   0.000000\n",
       "\n",
       "[2809 rows x 3 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = 2\n",
    "df_dists[df_dists[\"user1\"] == user].sort_values('eucl_dist', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422720"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 2\n",
    "min_rating = 7\n",
    "movies_to_analyze[user_id][movies_to_analyze[user_id] >= min_rating].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    La sortie des usines Lumière (1895)\n",
       "2          The Arrival of a Train (1896)\n",
       "Name: movie, dtype: object"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ids = [10, 12]\n",
    "movies[movies['movie_id'].isin(movie_ids)]['movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      422720\n",
       "3      454876\n",
       "4      790636\n",
       "5      816711\n",
       "6     1091191\n",
       "7     1103275\n",
       "8     1322269\n",
       "9     1390411\n",
       "10    1398426\n",
       "11    1431045\n",
       "12    1433811\n",
       "13    1454468\n",
       "14    1535109\n",
       "15    1675434\n",
       "16    1798709\n",
       "17    2017038\n",
       "18    2024544\n",
       "19    2294629\n",
       "20    2361509\n",
       "22    2726560\n",
       "23    2883512\n",
       "24    3079380\n",
       "Name: movie_id, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 2\n",
    "min_rating=7\n",
    "\n",
    "user_items.query(\"user_id == @user_id and rating >= @min_rating\")['movie_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "VWzHF9Jf1TuT"
   },
   "outputs": [],
   "source": [
    "def find_closest_neighbors(user):\n",
    "    '''\n",
    "    INPUT:\n",
    "        user - (int) the user_id of the individual you want to find the closest users\n",
    "    OUTPUT:\n",
    "        closest_neighbors - an array of the id's of the users sorted from closest to farthest away\n",
    "    '''\n",
    "    # I treated ties as arbitrary and just kept whichever was easiest to keep using the head method\n",
    "    # You might choose to do something less hand wavy - order the neighbors\n",
    "    \n",
    "    \n",
    "    \n",
    "    return np.array(df_dists[df_dists[\"user1\"] == user].sort_values('eucl_dist')['user2'].to_list())[1:]\n",
    "    \n",
    "    \n",
    "    \n",
    "def movies_liked(user_id, min_rating=7):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id of an individual as int\n",
    "    min_rating - the minimum rating considered while still a movie is still a \"like\" and not a \"dislike\"\n",
    "    OUTPUT:\n",
    "    movies_liked - an array of movies the user has watched and liked\n",
    "    '''\n",
    "  \n",
    "    return movies_to_analyze[user_id][movies_to_analyze[user_id] >= min_rating].index\n",
    "\n",
    "\n",
    "def movie_names(movie_ids):\n",
    "    '''\n",
    "    INPUT\n",
    "    movie_ids - a list of movie_ids\n",
    "    OUTPUT\n",
    "    movies - a list of movie names associated with the movie_ids\n",
    "    \n",
    "    '''\n",
    "\n",
    "    return movies[movies['movie_id'].isin(movie_ids)]['movie']\n",
    "    \n",
    "    \n",
    "def make_recommendations(user, num_recs=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "        user - (int) a user_id of the individual you want to make recommendations for\n",
    "        num_recs - (int) number of movies to return\n",
    "    OUTPUT:\n",
    "        recommendations - a list of movies - if there are \"num_recs\" recommendations return this many\n",
    "                          otherwise return the total number of recommendations available for the \"user\"\n",
    "                          which may just be an empty list\n",
    "    '''\n",
    "    movies_seen = movies_watched(user).index\n",
    "    closest_neighbors = find_closest_neighbors(user)\n",
    "    recs = np.array([])\n",
    "    \n",
    "    for neighbor in closest_neighbors:\n",
    "        neigh_likes = movies_liked(neighbor)\n",
    "        new_recs = np.setdiff1d(neigh_likes, movies_seen, assume_unique = True)\n",
    "        \n",
    "        recs = np.unique(np.concatenate([new_recs, recs], axis = 0))\n",
    "        \n",
    "        if len(recs) > num_recs - 1:\n",
    "            break\n",
    "    return movie_names(recs).to_list()\n",
    "\n",
    "\n",
    "def all_recommendations(list_of_users, num_recs=10):\n",
    "    '''\n",
    "    INPUT \n",
    "        num_recs (int) the (max) number of recommendations for each user\n",
    "    OUTPUT\n",
    "        all_recs - a dictionary where each key is a user_id and the value is an array of recommended movie titles\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    all_recs = {}\n",
    "    \n",
    "    for user in movies_seen:\n",
    "        all_recs[user] = make_recommendations(user, num_recs=10)\n",
    "    \n",
    "    \n",
    "    return all_recs\n",
    "\n",
    "# all_recs = all_recommendations(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Philadelphia (1993)',\n",
       " 'Training Day (2001)',\n",
       " 'About Schmidt (2002)',\n",
       " 'Insomnia (2002)',\n",
       " 'The United States of Leland (2003)',\n",
       " 'Shattered Glass (2003)',\n",
       " 'Man on Fire (2004)',\n",
       " 'Flipped (2010)',\n",
       " 'Silver Linings Playbook (2012)',\n",
       " 'Lawless (2012)',\n",
       " '50/50 (2011)',\n",
       " 'Crazy, Stupid, Love. (2011)',\n",
       " 'The Perks of Being a Wallflower (2012)',\n",
       " 'Before I Go to Sleep (2014)',\n",
       " 'Zero Dark Thirty (2012)',\n",
       " 'American Hustle (2013)',\n",
       " 'Django Unchained (2012)',\n",
       " 'Side Effects (2013)',\n",
       " 'Gone Girl (2014)',\n",
       " 'Enough Said (2013)',\n",
       " 'Nightcrawler (2014)']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = 2\n",
    "make_recommendations(user)\n",
    "# movies_seen = movies_watched(user).index\n",
    "# closest_neighbors = find_closest_neighbors(user)\n",
    "# neigh_likes = movies_liked(closest_neighbors[0])\n",
    "\n",
    "# movie_names(np.setdiff1d(neigh_likes, movies_seen))\n",
    "\n",
    "# neigh_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = 1\n",
    "find_closest_neighbors(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendations(user, num_recs=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "        user - (int) a user_id of the individual you want to make recommendations for\n",
    "        num_recs - (int) number of movies to return\n",
    "    OUTPUT:\n",
    "        recommendations - a list of movies - if there are \"num_recs\" recommendations return this many\n",
    "                          otherwise return the total number of recommendations available for the \"user\"\n",
    "                          which may just be an empty list\n",
    "    '''\n",
    "    recommendations = []\n",
    "    \n",
    "  \n",
    "    #we got the closest match\n",
    "    if len(find_closest_neighbors(user)) < 2:\n",
    "        return recommendations\n",
    "    neighbor_liked = movie_names(movies_liked(find_closest_neighbors(user)[1]))\n",
    "    movies_user_seen = movie_names(pd.DataFrame(movies_seen[user]).reset_index()['movie_id'])\n",
    "    recs = neighbor_liked[~neighbor_liked.isin(movies_user_seen)].to_list()\n",
    "    if len(recs) >= num_recs:\n",
    "        return recs[0:num_recs]\n",
    "    else:\n",
    "        return recs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_liked = movie_names(movies_liked(find_closest_neighbors(user)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_user_seen = movie_names(pd.DataFrame(movies_seen[user]).reset_index()['movie_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = neighbor_liked[~neighbor_liked.isin(movies_user_seen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7725                        Philadelphia (1993)\n",
      "9419                        Training Day (2001)\n",
      "10897                      About Schmidt (2002)\n",
      "11170                           Insomnia (2002)\n",
      "11507        The United States of Leland (2003)\n",
      "11783                    Shattered Glass (2003)\n",
      "11850                        Man on Fire (2004)\n",
      "14755                            Flipped (2010)\n",
      "15683            Silver Linings Playbook (2012)\n",
      "16502                            Lawless (2012)\n",
      "17011                              50/50 (2011)\n",
      "18368               Crazy, Stupid, Love. (2011)\n",
      "18892    The Perks of Being a Wallflower (2012)\n",
      "19342               Before I Go to Sleep (2014)\n",
      "19743                   Zero Dark Thirty (2012)\n",
      "19785                    American Hustle (2013)\n",
      "20115                   Django Unchained (2012)\n",
      "20970                       Side Effects (2013)\n",
      "22175                          Gone Girl (2014)\n",
      "22921                        Enough Said (2013)\n",
      "24385                       Nightcrawler (2014)\n",
      "Name: movie, dtype: object\n"
     ]
    }
   ],
   "source": [
    "user = 2\n",
    "num_recs = 50\n",
    "list_of_mov = make_recommendations(user)\n",
    "print(list_of_mov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "rrg_PCgu1TuT"
   },
   "outputs": [],
   "source": [
    "# This loads our solution dictionary so you can compare results\n",
    "all_recs_sol = pd.read_pickle(\"all_recs.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Philadelphia (1993)',\n",
       " 'Training Day (2001)',\n",
       " 'About Schmidt (2002)',\n",
       " 'Insomnia (2002)',\n",
       " 'The United States of Leland (2003)',\n",
       " 'Shattered Glass (2003)',\n",
       " 'Man on Fire (2004)',\n",
       " 'Flipped (2010)',\n",
       " 'Silver Linings Playbook (2012)',\n",
       " 'Lawless (2012)',\n",
       " '50/50 (2011)',\n",
       " 'Crazy, Stupid, Love. (2011)',\n",
       " 'The Perks of Being a Wallflower (2012)',\n",
       " 'Before I Go to Sleep (2014)',\n",
       " 'Zero Dark Thirty (2012)',\n",
       " 'American Hustle (2013)',\n",
       " 'Django Unchained (2012)',\n",
       " 'Side Effects (2013)',\n",
       " 'Gone Girl (2014)',\n",
       " 'Enough Said (2013)',\n",
       " 'Nightcrawler (2014)']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_recs_sol[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "tR5UsW1m1TuT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you made it here, you now have recommendations for many users using collaborative filtering!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"images/greatjob.webp\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert all_recs_sol[2] == make_recommendations(2), \"Oops!  Your recommendations for user 2 didn't match ours.\"\n",
    "assert all_recs_sol[26] == make_recommendations(26), \"Oops!  It actually wasn't possible to make any recommendations for user 26.\"\n",
    "assert all_recs_sol[1503] == make_recommendations(1503), \"Oops! Looks like your solution for user 1503 didn't match ours.\"\n",
    "print(\"If you made it here, you now have recommendations for many users using collaborative filtering!\")\n",
    "HTML('<img src=\"images/greatjob.webp\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8xR0qpp1TuT"
   },
   "source": [
    "### Now What?\n",
    "\n",
    "If you made it this far, you have successfully implemented a solution to making recommendations using collaborative filtering. \n",
    "\n",
    "`8.` Let's do a quick recap of the steps taken to obtain recommendations using collaborative filtering.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "id": "cgzCCoPx1TuT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's right! All of your solutions look good!\""
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check your understanding of the results by correctly filling in the dictionary below\n",
    "a = \"pearson's correlation and spearman's correlation\"\n",
    "b = 'item based collaborative filtering'\n",
    "c = \"there were too many ratings to get a stable metric\"\n",
    "d = 'user based collaborative filtering'\n",
    "e = \"euclidean distance and pearson's correlation coefficient\"\n",
    "f = \"manhattan distance and euclidean distance\"\n",
    "g = \"spearman's correlation and euclidean distance\"\n",
    "h = \"the spread in some ratings was zero\"\n",
    "i = 'content based recommendation'\n",
    "\n",
    "sol_dict = {\n",
    "    'The type of recommendation system implemented here was a ...': d,# letter here,\n",
    "    'The two methods used to estimate user similarity were: ': e,# letter here,\n",
    "    'There was an issue with using the correlation coefficient.  What was it?': h# letter here\n",
    "}\n",
    "\n",
    "t.test_recs(sol_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELQqg-qX1TuT"
   },
   "source": [
    "Additionally, let's take a closer look at some of the results.  There are two solution files that you read in to check your results, and you created these objects\n",
    "\n",
    "* **df_dists** - a dataframe of user1, user2, euclidean distance between the two users\n",
    "* **all_recs_sol** - a dictionary of all recommendations (key = user, value = list of recommendations)  \n",
    "\n",
    "`9.` Use these two objects along with the cells below to correctly fill in the dictionary below and complete this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "id": "bGFwnpGP1TuU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's right! All of your solutions look good!\""
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 567\n",
    "b = 1503\n",
    "c = 1319\n",
    "d = 1325\n",
    "e = 2526710\n",
    "f = 0\n",
    "g = 'Use another method to make recommendations - content based, knowledge based, or model based collaborative filtering'\n",
    "\n",
    "sol_dict2 = {\n",
    "    'For how many pairs of users were we not able to obtain a measure of similarity using correlation?': e, # letter here,\n",
    "    'For how many pairs of users were we not able to obtain a measure of similarity using euclidean distance?': f, # letter here,\n",
    "    'For how many users were we unable to make any recommendations for using collaborative filtering?': c,# letter here,\n",
    "    'For how many users were we unable to make 10 recommendations for using collaborative filtering?': d,# letter here,\n",
    "    'What might be a way for us to get 10 recommendations for every user?': g# letter here   \n",
    "}\n",
    "\n",
    "t.test_recs2(sol_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23512"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_recs_sol.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDict = { key:value for (key,value) in all_recs_sol.items() if len(value) < 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1325"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2880677574"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_possible_pairs - df_dists.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(compute_correlation(user1, user2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "id": "fCskaoX01TuU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the cells below for any work you need to do!\n",
    "\n",
    "compute_correlation(2,104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtXQ-BRR1TuU"
   },
   "outputs": [],
   "source": [
    "# Users without recs\n",
    "compute_correlation(2,104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42mnU5-t1TuU"
   },
   "outputs": [],
   "source": [
    "# NaN euclidean distance values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sf141r3H1TuU"
   },
   "outputs": [],
   "source": [
    "# Users with less than 10 recs\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Collaborative Filtering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
